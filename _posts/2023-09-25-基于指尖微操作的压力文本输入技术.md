---
title: 基于指尖微操作的压力文本输入技术
layout: post
description:
category: 科研长河
---

## Intro

这次科研历程自21年暑假始，中间历经多次波折，最后还是仓促结束于22年秋天。

## 金手指 Golden Finger

该项目起源于舍友的*金手指*项目，最开始是致力于研制一款智能指套，通过侦测用户手指尖（一般是食指）的压力变化（一般是手指与某一平面作用），来达到交互的目的。该项目从*学术新星*开始，又成为了舍友的挑战杯项目，最后决定整理成论文冲击CHI[^1]。考虑到需要增加新的交互方式和现有人手问题，舍友在暑假的某一天通过微信问我：

> 要不要过来帮我们赶paper？

当时我还在家里做上一份研究的数据录入[^2]，由于是同一个学长带，我勉强答应了下来。一来现在在做的项目也要回学校线下讨论好推进，二来我蹭一篇paper也对之后寻找出路有益。由于我对他们之前的项目有所耳闻，所以理解整个流程并不算困难。在7月底，我提前收假回到了学校[^3]。

[^1]: CHI, Conference on Human Factors in Computing Systems, 人机交互领域顶会。
[^2]: 自那之后之前那份项目就无人问津了。
[^3]: 说来也巧，如果那时候不提前回校，再迟几天就因为疫情爆发而回不了了。

## 指尖交互 Golden Gain

从挑战杯的项目得到的也只是指尖的压力数据，如何设计有效的交互成为了这一个多月的重点。而大家希望能使用这个压力膜控制一个光标，有了光标之后不外乎几个层次的交互：光标移动、手势交互、文本输入。最初我们打算就聚焦于光标移动，因为本身这种交互的硬件就足够新颖了，关键在于怎么稳定地提供光标指向的交互。而光标移动的任务无外乎几个维度上的考虑：绝对还是相对、显控比（Control-Display Ratio, CdRatio）、移动外的交互（点击、双击、拖拽、滑动等等）。前两个其实是交互设计的核心：如何将用户指尖的移动映射到屏幕上的光标的移动。

这一方面我们主要参考的工作是AutoGain[^4]，一个基于用户使用过程中不断自适应显控比的系统。我主要负责的，是将硬件提供的压力信号，具体来说是一个8×8的矩阵，输出为实时的光标坐标，并且编写一个前端展示出来。在压力矩阵转换坐标的过程中，有几个难点：

- 如何处理压力矩阵？作为一个二维的矩阵来计算还是压缩为一个平均值？
- 如何将AutoGain的框架应用上来？需不需要设计其他的模式？
- 压力矩阵的分辨率是否满足任务需求？

对于压力矩阵，其实两种方法我们都尝试了。如果看待为矩阵，那么我们需要一个从二维矩阵到屏幕坐标的映射，当时甚至还尝试了诸如二维插值、高次多项式拟合之类的方法，效果欠佳；如果取平均值，那么其实也就获得了用户目前所在的指尖坐标系的坐标，从这个坐标到屏幕坐标的映射是自然的。对于AutoGain，我前几周都在根据其论文使用python复现其框架，后面发现其实AutoGain在我们的工作中其实是一个点睛之笔而非必要组成部分，我们可以先实现一个朴素的绝对或者相对的模式，再考虑实现混合的或者自适应的显控比映射。最后是压力矩阵的分辨率，当时我们采用的硬件在指尖做到64个压力单元其实已经接近极限了，但是这个压力矩阵实际上来说也并没有太能满足交互的需求，加上重复实验的压力下硬件的负荷超出了其使用极限，到后期磨损也极大地影响了数据质量。

在狙击论文的最后阶段，实验硬件的质量和效果极大地影响了进度，以至于一直没有做出满意的效果，最终论文也没能赶得上会议投稿。现在想来除了硬件的问题之外，我们当时似乎过于追求最后达到的效果，而没有先做出一个简单朴素的Demo，再在这之上扩展一些更高级的交互技术。但是这个项目并不会因为投稿的截至而结束，而是会继续展望之后的会议。

[^4]: [AutoGain: Gain Function Adaptation with Submovement Efficiency Optimization](https://dl.acm.org/doi/10.1145/3313831.3376244).

## 指尖输入 Golden Touch

在折戟CHI后，我们的项目开始发生了奇妙的转变。学长由于其他项目而很少参与我们之后的讨论，基本上我们两个本科生相当于直接由导师带着。在经过几次讨论之后，项目的方向从光标移动移动到了文本输入。

### 字母输入 Character Level Input

最简单、容易实现的文本输入自然是按照字母输入。而为了将这个交互技术从硬件条件中抽出，避免之前出现的硬件问题，我们选择了Sensel Morph[^5]作为新的输入设备。这个压力采集设备能够采集到更高分辨率和帧率的压力数据，我们使用白纸刻画出指尖的形状，将压力板的采集区域局限于指尖这一部分，模拟了佩戴我们之前压力膜指套的数据，从而获得了稳定的硬件条件和更高的数据质量。这时我们将书写的方法规定为手指在板子上**滚动**，为了和佩戴指套的操作相匹配。

最初我们做pilot study，采集了几个同学的使用这个硬件书写a、b、c、d小写字母的压力数据[^6]。一个方法是使用简单粗暴的机器学习方法来做分类和预测，在当时数据量比较小的情况下表现地还算不错，并且实时Demo也能够跑得起来。但是当时并未继续沿着这个方法研究，可能是因为缺乏解释性、在算法上的贡献不够等等。另一个方法是通过分析数据的特征（例如特殊模式、极值等等），开发一些白盒的算法来进行分类和预测。我们想从后者上打开思路，毕竟这个任务可能非常简单，并且利于扩充论文的体量。

[^5]: [商用压力板设备](https://morph.sensel.com/).
[^6]: 其中一个同学我们一直招募作为使用的被试，可能总计需要发八到十份被试费了。

### 滑行输入 Gesture Typing

由于在指尖上控制所谓光标完成逐个字母的输入似乎过于简单并且毫无实用性，我们决定将目标放在滑行输入上。滑行输入即将光标扫过的路径和字母连线路径进行*距离*的计算，将最近的*匹配*给出作为输入结果。这个和之前的SHARK^2有很大的关系。显而易见的，最直接的方式是将我们压力板上采集到的平均值在时间序列上的路径和词库进行逐一匹配，输出最接近的答案。虽然流程非常清晰，但是其中存在几个核心问题：

- 用户的指尖运动控制得如何？用户的能力是否能完成该任务？
- 用户的输入需要预处理吗？如何处理？

这其实来源于我们pilot study中所遇到的问题。一是有的用户很难学会在我们预设的板子上设定的使用方法，可能用户在指尖上的运动不足以完成模拟在QWERTY键盘上的滑行输入；二是用户的输入很容易有开头、结尾、和犹豫区。开头和结尾很容易理解，用户可能在书写的时候并没有提前准备好路径，从而在书写开始时才去思考，造成开头的噪声；结尾部分同理。最难处理的是中间的犹豫区，即用户可能在书写过程中出现噪声：包括但不限于某些部分过快过慢、某些部分幅度过大过小、某些部分因思考停滞。像滑行输入这种技术下，过程性的噪声的影响非常大，故我们需要提醒用户对自己即将书写的路径有清晰的规划。这在无形中增加了用户的负担。我们采用了经典的McKanzie的文本输入词库[^7]，收集了一定量的用户滑行输入的数据，之后一段时间我们都在探索算法。

算法可以说是在简单流程上的缝缝补补。理想情况下，我们借鉴SHARK^2的算法，配合我们的词库应该能达到比较好的效果，但其实并没有，调参后效果也提升有限。后来我邂逅了DTW，一个命中注定的算法[^8]，主题改用DTW来做距离的计算和匹配。在此基础上，我们又扩充了对于开始和结尾段的噪声消除、对用户的输入路径进行特征提取和整合、对DTW匹配的*标准路径*的优化等等算法，其中大部分都由我当时的室友兼科研伙伴在寒假左右推进[^9]。最后他将我们收集的数据，调参到了60%~70%的Top1正确率。尽管这在这样低的用户能力下很高了，但作为一种交互技术来说远远不够。

[^7]: [Phrase Sets for Evaluating Text Entry Techniques](https://www.yorku.ca/mack/chi03b.html).
[^8]: Dynamic Time Warping，动态时间规整算法，一种对时间序列的相似性进行度量的动态规划算法。命中注定是之后的项目老是频繁用到该算法。
[^9]: 说实话当时他在一些零零碎碎的算法和数据处理的优化上也是费了很多功夫，寒假的时候包括寒假之前，我们的汇报和讨论都非常地紧张，进展却因为各种原因非常缓慢，所以当时调出来六七成的正确率已经惊为天人了。并且做到这个时候大家也都很累了，可能需要一些时间来思考这个项目的始末和未来的规划。

### 笔画输入 Direction Write

寒假回来，由于滑行输入的正确率太低，我们需要设计新的输入方式。在受到EdgeWrite[^10]的启发后，我设计了一种基于方向笔画的字母输入方式。将每个字母分解成若干离散方向的组合，再指导用户逐一写出这些方向的组合，从而达到输入字母的目的。这种方式首先将用户的输入降维、离散处理了，从而对用户的输入噪声的敏感性降低。并且这对用户的输入能力的要求也降低了。在简单的pilot study后，我们决定将重心移到这上面来。

于是目前的论文故事就比较清晰，并且实现难度**似乎**也更低了。首先我们需要衡量用户输入方向的能力，具体体现为用户使用这种技术时，能够区分多少种方向。其次我们提出一种基于方向笔画的字母输入技术，设计了字母的离散笔画，并且这种设计也符合一些设计理念。然后我们收集了用户使用这种输入方式的数据并且进行算法模拟，最后进行用户实验来评估。似乎这个故事很好听，行云流水，也非常地有贡献，但是这个计划上飘荡着两朵乌云：

- 实际使用中的输入正确率如何？
- 这种技术的实用性如何？有什么具体的适用场景？

这其实也成为了之后该项目未能完成的两大痛点。虽然降低了输入难度，但是当用户无法适应这种输入方式的时候，正确率仍然很难提升，而这一点在用户之间呈现出极大的方差。这些难以学习的被试的表现极大地拉低了正确率，我们前后做了近二十位被试，平均下来的正确率仍然很低。他们常常需要我们进行逐步的指导和及时的提醒，才能勉强达到总体的平均水平。至于实用性，是一直被争论的一个点。我们开始设想的时候，想到强调*隐私性*会使这个故事比较好讲，因为从一开始我们觉得指尖这种小动作输入能够带来更高的隐私性，从而在公共空间进行输入时能够更好地保护个人隐私。但是这需要我们在论文中追加特定的实验来说明，否则最多只能起到画龙点睛的作用。而不谈隐私性，似乎这种输入技术在当下没有使用的场景，从而给论文带来了极大的基础困难。

在努力挣扎了两个月的用户评估实验后，实验结果仍然没有达到期望，所以似乎这种交互方式也走到了探索的尽头。又恰逢毕业年我们开始毕业设计的选题和研究，我们便想采取一直搁置的退路——将目前的算法和进度交付给其他同学来完成。一是我们目前的探索方向很多，即使别人来做这个方向也能提前排除做不出来的方向；二是基于目前这套硬件设备的情况下，我们的实验平台、数据处理的一些框架的部分算法都能继续使用，从而接手的同学能够很快上手。

[^10]: [EdgeWrite: a stylus-based text entry method designed for high accuracy and stability of motion](https://dl.acm.org/doi/abs/10.1145/964696.964703).

## 微操作输入 TinyWrite

在项目移交其他同学之后，我们又参加了最初的几次讨论，而之后也只是偶尔跟进了项目的状态。到其完成论文写作和投稿为止，又与之前的交互设计和故事有了很大的改变。首先是书写方式，不再是之前强调的*滚动*，而是允许滑动，但滑动范围要尽量的小；其次是从用户的指尖方向变成了用户书写时对书写范围的感知，即用户最小能在多大的面积里书写；第三是强调了隐私性，补充了对应的实验，而不是以正确率为唯一指标。我后来也参加了一些项目验收和评估实验等环节，体验了他们完全使用神经网络预测来做黑盒输入的效果和防偷窥效果，感觉就正确率来说，大抵是接近这种交互输入的极限了。

## 注释 Notes
